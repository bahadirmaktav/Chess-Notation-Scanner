{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze empty lists for train and test data\n",
    "x_train, y_train, x_test, y_test = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "################################# EMNIST DATA FILTER AND LOAD ##################################\n",
    "\n",
    "# Loads emnist/byclass dataset\n",
    "(x_train_emnist, y_train_emnist), (x_test_emnist, y_test_emnist) = tfds.as_numpy(tfds.load('emnist', split=['train', 'test'], batch_size=-1, as_supervised=True))\n",
    "\n",
    "# Reshape array (697932, 28, 28, 1) to (697932, 28, 28) before filtering\n",
    "x_train_emnist = x_train_emnist.reshape((len(x_train_emnist), len(x_train_emnist[0]), len(x_train_emnist[0][0])))\n",
    "x_test_emnist = x_test_emnist.reshape((len(x_test_emnist), len(x_test_emnist[0]), len(x_test_emnist[0][0])))\n",
    "\n",
    "# Filter train and test data for chess annotation symbols/characters\n",
    "for i in range(len(x_train_emnist)):\n",
    "    if ((y_train_emnist[i] >= 0) & (y_train_emnist[i] < 9)):\n",
    "        x_train.append(cv2.transpose(x_train_emnist[i]))\n",
    "        y_train.append(y_train_emnist[i])\n",
    "    elif y_train_emnist[i] == 11:\n",
    "        x_train.append(cv2.transpose(x_train_emnist[i]))\n",
    "        y_train.append(20)\n",
    "    elif y_train_emnist[i] == 20:\n",
    "        x_train.append(cv2.transpose(x_train_emnist[i]))\n",
    "        y_train.append(17)\n",
    "    elif y_train_emnist[i] == 23:\n",
    "        x_train.append(cv2.transpose(x_train_emnist[i]))\n",
    "        y_train.append(21)\n",
    "    elif y_train_emnist[i] == 26:\n",
    "        x_train.append(cv2.transpose(x_train_emnist[i]))\n",
    "        y_train.append(18)\n",
    "    elif y_train_emnist[i] == 27:\n",
    "        x_train.append(cv2.transpose(x_train_emnist[i]))\n",
    "        y_train.append(19)\n",
    "    elif ((y_train_emnist[i] >= 36) & (y_train_emnist[i] < 44)):\n",
    "        x_train.append(cv2.transpose(x_train_emnist[i]))\n",
    "        y_train.append(y_train_emnist[i] - 27)\n",
    "    elif y_train_emnist[i] == 59:\n",
    "        x_train.append(cv2.transpose(x_train_emnist[i]))\n",
    "        y_train.append(23)\n",
    "\n",
    "for i in range(len(x_test_emnist)):\n",
    "    if ((y_test_emnist[i] >= 0) & (y_test_emnist[i] < 9)):\n",
    "        x_test.append(cv2.transpose(x_test_emnist[i]))\n",
    "        y_test.append(y_test_emnist[i])\n",
    "    elif y_test_emnist[i] == 11:\n",
    "        x_test.append(cv2.transpose(x_test_emnist[i]))\n",
    "        y_test.append(20)\n",
    "    elif y_test_emnist[i] == 20:\n",
    "        x_test.append(cv2.transpose(x_test_emnist[i]))\n",
    "        y_test.append(17)\n",
    "    elif y_test_emnist[i] == 23:\n",
    "        x_test.append(cv2.transpose(x_test_emnist[i]))\n",
    "        y_test.append(21)\n",
    "    elif y_test_emnist[i] == 26:\n",
    "        x_test.append(cv2.transpose(x_test_emnist[i]))\n",
    "        y_test.append(18)\n",
    "    elif y_test_emnist[i] == 27:\n",
    "        x_test.append(cv2.transpose(x_test_emnist[i]))\n",
    "        y_test.append(19)\n",
    "    elif ((y_test_emnist[i] >= 36) & (y_test_emnist[i] < 44)):\n",
    "        x_test.append(cv2.transpose(x_test_emnist[i]))\n",
    "        y_test.append(y_test_emnist[i] - 27)\n",
    "    elif y_test_emnist[i] == 59:\n",
    "        x_test.append(cv2.transpose(x_test_emnist[i]))\n",
    "        y_test.append(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "################################# HASY DATA FILTER AND LOAD ##################################\n",
    "\n",
    "# Set hasy dataset root folder\n",
    "hasy_root_path = '.'\n",
    "\n",
    "# Get image file path list and related label list for images contains #,-,+ symbols\n",
    "loaded_df_hasy = pd.read_csv(hasy_root_path + '\\\\hasy-data-labels.csv')\n",
    "loaded_array_hasy = loaded_df_hasy.to_numpy()\n",
    "label_filter = np.where((loaded_array_hasy[:,2] == '\\#') | (loaded_array_hasy[:,2] == '-') | (loaded_array_hasy[:,2] == '+'))\n",
    "loaded_array_hasy_filtered = loaded_array_hasy[label_filter]\n",
    "\n",
    "# Split index set for %80 / %20 to create train and test data\n",
    "split_index = int(len(loaded_array_hasy_filtered) * 0.8)\n",
    "train_data_hasy, test_data_hasy = np.split(loaded_array_hasy_filtered, [split_index])\n",
    "x_train_hasy, y_train_hasy = train_data_hasy[:,0], train_data_hasy[:,2]\n",
    "x_test_hasy, y_test_hasy = test_data_hasy[:,0], test_data_hasy[:,2]\n",
    "\n",
    "# Fill x_train and y_train data with image and label data comes from hasy dataset\n",
    "for i in range(len(x_train_hasy)):\n",
    "    abs_image_path = hasy_root_path + x_train_hasy[i]\n",
    "    image = cv2.imread(abs_image_path)\n",
    "    if image is not None:\n",
    "        image = cv2.resize(image, (28, 28))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = 255 - image\n",
    "        x_train.append(image)\n",
    "        if y_train_hasy[i] == '+':\n",
    "            y_train.append(24)\n",
    "        elif y_train_hasy[i] == '-':\n",
    "            y_train.append(22)\n",
    "        else: # y_train_hasy[i] = '/#'\n",
    "            y_train.append(25)\n",
    "\n",
    "# Fill x_test and y_test data with image and label data comes from hasy dataset\n",
    "for i in range(len(x_test_hasy)):\n",
    "    abs_image_path = hasy_root_path + x_test_hasy[i]\n",
    "    image = cv2.imread(abs_image_path)\n",
    "    if image is not None:\n",
    "        image = cv2.resize(image, (28, 28))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = 255 - image\n",
    "        x_test.append(image)\n",
    "        if y_test_hasy[i] == '+':\n",
    "            y_test.append(24)\n",
    "        elif y_test_hasy[i] == '-':\n",
    "            y_test.append(22)\n",
    "        else: # y_test_hasy[i] = '/#'\n",
    "            y_test.append(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Gets size information of train/test data and height/width of image \n",
    "train_data_size   = len(x_train)\n",
    "test_data_size    = len(x_test)\n",
    "height_pixel_size = len(x_train[0])\n",
    "width_pixel_size  = len(x_train[0][0])\n",
    "\n",
    "print(f'train_data_size: {train_data_size}')\n",
    "print(f'test_data_size: {test_data_size}')\n",
    "print(f'height_pixel_size: {height_pixel_size}')\n",
    "print(f'width_pixel_size: {width_pixel_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "####################################### DATASET CSV SAVE #######################################\n",
    "\n",
    "# Reshape the array to 2D (697932, 784) for CSV\n",
    "x_train_flattened = x_train.reshape(train_data_size, -1)\n",
    "x_test_flattened = x_test.reshape(test_data_size, -1)\n",
    "\n",
    "# Saves train image data to csv file\n",
    "df_train_image_data = pd.DataFrame(x_train_flattened)\n",
    "df_train_image_data.to_csv('dataset\\\\train_image_data.csv', index=False)\n",
    "\n",
    "# Saves train label data to csv file\n",
    "df_train_label_data = pd.DataFrame(y_train)\n",
    "df_train_label_data.to_csv('dataset\\\\train_label_data.csv', index=False)\n",
    "\n",
    "# Saves test image data to csv file\n",
    "df_test_image_data = pd.DataFrame(x_test_flattened)\n",
    "df_test_image_data.to_csv('dataset\\\\test_image_data.csv', index=False)\n",
    "\n",
    "# Saves test label data to csv file\n",
    "df_test_label_data = pd.DataFrame(y_test)\n",
    "df_test_label_data.to_csv('dataset\\\\test_label_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "####################################### DATASET CSV LOAD #######################################\n",
    "\n",
    "# Loads train image data and verify with initial data\n",
    "loaded_df_train_image_data = pd.read_csv('dataset\\\\train_image_data.csv')\n",
    "loaded_array_train_image_data = loaded_df_train_image_data.to_numpy().reshape(train_data_size, height_pixel_size, width_pixel_size)\n",
    "print(f\"train image data {np.array_equal(x_train, loaded_array_train_image_data)}\")\n",
    "\n",
    "# Loads train label data and verify with initial data\n",
    "loaded_df_train_label_data = pd.read_csv('dataset\\\\train_label_data.csv')\n",
    "loaded_array_train_label_data = loaded_df_train_label_data.to_numpy().reshape(train_data_size)\n",
    "print(f\"train label data {np.array_equal(y_train, loaded_array_train_label_data)}\")\n",
    "\n",
    "# Loads test image data and verify with initial data\n",
    "loaded_df_test_image_data = pd.read_csv('dataset\\\\test_image_data.csv')\n",
    "loaded_array_test_image_data = loaded_df_test_image_data.to_numpy().reshape(test_data_size, height_pixel_size, width_pixel_size)\n",
    "print(f\"test image data {np.array_equal(x_test, loaded_array_test_image_data)}\")\n",
    "\n",
    "# Loads test label data and verify with initial data\n",
    "loaded_df_test_label_data = pd.read_csv('dataset\\\\test_label_data.csv')\n",
    "loaded_array_test_label_data = loaded_df_test_label_data.to_numpy().reshape(test_data_size)\n",
    "print(f\"test label data {np.array_equal(y_test, loaded_array_test_label_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests to determine values of characters\n",
    "selected_data_index = 5375\n",
    "plt.imshow(x_train[selected_data_index], cmap='gray')\n",
    "# plt.imshow(cv2.transpose(x_train[selected_data_index]), cmap='gray')\n",
    "# plt.imshow(np.flipud(np.rot90(x_train_reshaped[selected_data_index], k=1)), cmap='gray')\n",
    "print(y_train[selected_data_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
